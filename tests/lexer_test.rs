use open_system_verilog::keywords::Keyword;
use open_system_verilog::lexer::{FilePosition, Lexer};
use open_system_verilog::operators::Operator;
use open_system_verilog::punctuation::Punctuation;
use open_system_verilog::token::{
    BuildToken, CharacterSequenceToken, KeywordToken, OperatorToken, PunctuationToken,
    StringLiteralToken, Token,
};

#[test]
fn should_lex_svaunit_seq() {
    let expected_tokens = vec![
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(21, 1)),
        CharacterSequenceToken::build_token(String::from("ifndef"), FilePosition::new(21, 2)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 9)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 10)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 11)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 12)),
        CharacterSequenceToken::build_token(String::from("IF"), FilePosition::new(21, 13)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 15)),
        CharacterSequenceToken::build_token(String::from("SVAUNIT"), FilePosition::new(21, 16)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 23)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 24)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 25)),
        CharacterSequenceToken::build_token(String::from("SEQ"), FilePosition::new(21, 26)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(21, 29)),
        CharacterSequenceToken::build_token(String::from("SV"), FilePosition::new(21, 30)),
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(22, 1)),
        CharacterSequenceToken::build_token(String::from("define"), FilePosition::new(22, 2)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 9)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 10)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 11)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 12)),
        CharacterSequenceToken::build_token(String::from("IF"), FilePosition::new(22, 13)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 15)),
        CharacterSequenceToken::build_token(String::from("SVAUNIT"), FilePosition::new(22, 16)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 23)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 24)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 25)),
        CharacterSequenceToken::build_token(String::from("SEQ"), FilePosition::new(22, 26)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(22, 29)),
        CharacterSequenceToken::build_token(String::from("SV"), FilePosition::new(22, 30)),
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(24, 1)),
        KeywordToken::build_token(Keyword::Include, FilePosition::new(24, 2)),
        StringLiteralToken::build_token(
            String::from("sv/svaunit_pkg.sv"),
            FilePosition::new(24, 11),
        ),
        KeywordToken::build_token(Keyword::Import, FilePosition::new(25, 1)),
        CharacterSequenceToken::build_token(String::from("svaunit"), FilePosition::new(25, 8)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(25, 15)),
        CharacterSequenceToken::build_token(String::from("pkg"), FilePosition::new(25, 16)),
        PunctuationToken::build_token(Punctuation::Colon, FilePosition::new(25, 19)),
        PunctuationToken::build_token(Punctuation::Colon, FilePosition::new(25, 20)),
        OperatorToken::build_token(Operator::Multiplication, FilePosition::new(25, 21)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(25, 22)),
        KeywordToken::build_token(Keyword::Class, FilePosition::new(28, 1)),
        CharacterSequenceToken::build_token(String::from("svaunit"), FilePosition::new(28, 7)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(28, 14)),
        CharacterSequenceToken::build_token(String::from("seq"), FilePosition::new(28, 15)),
        KeywordToken::build_token(Keyword::Extends, FilePosition::new(28, 19)),
        CharacterSequenceToken::build_token(String::from("svaunit"), FilePosition::new(28, 27)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(28, 34)),
        CharacterSequenceToken::build_token(String::from("base"), FilePosition::new(28, 35)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(28, 39)),
        KeywordToken::build_token(Keyword::Sequence, FilePosition::new(28, 40)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(28, 48)),
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(29, 4)),
        CharacterSequenceToken::build_token(String::from("uvm"), FilePosition::new(29, 5)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(29, 8)),
        CharacterSequenceToken::build_token(String::from("object"), FilePosition::new(29, 9)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(29, 15)),
        CharacterSequenceToken::build_token(String::from("utils"), FilePosition::new(29, 16)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(29, 21)),
        CharacterSequenceToken::build_token(String::from("svaunit"), FilePosition::new(29, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(29, 29)),
        CharacterSequenceToken::build_token(String::from("seq"), FilePosition::new(29, 30)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(29, 33)),
        KeywordToken::build_token(Keyword::Function, FilePosition::new(36, 4)),
        KeywordToken::build_token(Keyword::New, FilePosition::new(36, 13)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(36, 16)),
        KeywordToken::build_token(Keyword::String, FilePosition::new(36, 17)),
        CharacterSequenceToken::build_token(String::from("name"), FilePosition::new(36, 24)),
        OperatorToken::build_token(Operator::BinaryAssignment, FilePosition::new(36, 29)),
        StringLiteralToken::build_token(String::from("svaunit_seq"), FilePosition::new(36, 31)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(36, 44)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(36, 45)),
        KeywordToken::build_token(Keyword::Super, FilePosition::new(37, 7)),
        PunctuationToken::build_token(Punctuation::Period, FilePosition::new(37, 12)),
        KeywordToken::build_token(Keyword::New, FilePosition::new(37, 13)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(37, 16)),
        CharacterSequenceToken::build_token(String::from("name"), FilePosition::new(37, 17)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(37, 21)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(37, 22)),
        KeywordToken::build_token(Keyword::Endfunction, FilePosition::new(40, 4)),
        KeywordToken::build_token(Keyword::Virtual, FilePosition::new(42, 4)),
        KeywordToken::build_token(Keyword::Task, FilePosition::new(42, 12)),
        CharacterSequenceToken::build_token(String::from("pre"), FilePosition::new(42, 17)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(42, 20)),
        CharacterSequenceToken::build_token(String::from("body"), FilePosition::new(42, 21)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(42, 25)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(42, 26)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(42, 27)),
        KeywordToken::build_token(Keyword::Super, FilePosition::new(43, 7)),
        PunctuationToken::build_token(Punctuation::Period, FilePosition::new(43, 12)),
        CharacterSequenceToken::build_token(String::from("pre"), FilePosition::new(43, 13)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(43, 16)),
        CharacterSequenceToken::build_token(String::from("body"), FilePosition::new(43, 17)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(43, 21)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(43, 22)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(43, 23)),
        KeywordToken::build_token(Keyword::Endtask, FilePosition::new(46, 4)),
        KeywordToken::build_token(Keyword::Virtual, FilePosition::new(48, 4)),
        KeywordToken::build_token(Keyword::Task, FilePosition::new(48, 12)),
        CharacterSequenceToken::build_token(String::from("body"), FilePosition::new(48, 17)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(48, 21)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(48, 22)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(48, 23)),
        KeywordToken::build_token(Keyword::Endtask, FilePosition::new(50, 4)),
        KeywordToken::build_token(Keyword::Endclass, FilePosition::new(51, 1)),
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(53, 1)),
        CharacterSequenceToken::build_token(String::from("endif"), FilePosition::new(53, 2)),
        Token::EOF(FilePosition::new(54, 1)),
    ];

    let file_path = "./programs/svaunit_seq.sv";
    let mut lexer = Lexer::open(file_path);

    let tokens = lexer.lex();

    for (i, token) in tokens.iter().enumerate() {
        assert_eq!(token, &expected_tokens[i]);
    }
}
