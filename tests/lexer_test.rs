use open_system_verilog::keywords::Keyword;
use open_system_verilog::lexer::{FilePosition, Lexer};
use open_system_verilog::operators::Operator;
use open_system_verilog::punctuation::Punctuation;
use open_system_verilog::token::{
    BuildToken, CharacterSequenceToken, KeywordToken, OperatorToken, PunctuationToken,
    StringLiteralToken, Token,
};

#[test]
fn should_lex_svaunit_seq() {
    let expected_tokens = vec![
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(1, 21)),
        CharacterSequenceToken::build_token(String::from("ifndef"), FilePosition::new(2, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(9, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(10, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(11, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(12, 21)),
        CharacterSequenceToken::build_token(String::from("IF"), FilePosition::new(13, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(15, 21)),
        CharacterSequenceToken::build_token(String::from("SVAUNIT"), FilePosition::new(16, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(23, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(24, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(25, 21)),
        CharacterSequenceToken::build_token(String::from("SEQ"), FilePosition::new(26, 21)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(29, 21)),
        CharacterSequenceToken::build_token(String::from("SV"), FilePosition::new(30, 21)),
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(1, 22)),
        CharacterSequenceToken::build_token(String::from("define"), FilePosition::new(2, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(9, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(10, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(11, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(12, 22)),
        CharacterSequenceToken::build_token(String::from("IF"), FilePosition::new(13, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(15, 22)),
        CharacterSequenceToken::build_token(String::from("SVAUNIT"), FilePosition::new(16, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(23, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(24, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(25, 22)),
        CharacterSequenceToken::build_token(String::from("SEQ"), FilePosition::new(26, 22)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(29, 22)),
        CharacterSequenceToken::build_token(String::from("SV"), FilePosition::new(30, 22)),
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(1, 24)),
        KeywordToken::build_token(Keyword::Include, FilePosition::new(2, 24)),
        StringLiteralToken::build_token(
            String::from("sv/svaunit_pkg.sv"),
            FilePosition::new(11, 24),
        ),
        KeywordToken::build_token(Keyword::Import, FilePosition::new(1, 25)),
        CharacterSequenceToken::build_token(String::from("svaunit"), FilePosition::new(8, 25)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(15, 25)),
        CharacterSequenceToken::build_token(String::from("pkg"), FilePosition::new(16, 25)),
        PunctuationToken::build_token(Punctuation::Colon, FilePosition::new(19, 25)),
        PunctuationToken::build_token(Punctuation::Colon, FilePosition::new(20, 25)),
        OperatorToken::build_token(Operator::Multiplication, FilePosition::new(21, 25)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(22, 25)),
        KeywordToken::build_token(Keyword::Class, FilePosition::new(1, 28)),
        CharacterSequenceToken::build_token(String::from("svaunit"), FilePosition::new(7, 28)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(14, 28)),
        CharacterSequenceToken::build_token(String::from("seq"), FilePosition::new(15, 28)),
        KeywordToken::build_token(Keyword::Extends, FilePosition::new(19, 28)),
        CharacterSequenceToken::build_token(String::from("svaunit"), FilePosition::new(27, 28)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(34, 28)),
        CharacterSequenceToken::build_token(String::from("base"), FilePosition::new(35, 28)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(39, 28)),
        KeywordToken::build_token(Keyword::Sequence, FilePosition::new(40, 28)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(48, 28)),
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(4, 29)),
        CharacterSequenceToken::build_token(String::from("uvm"), FilePosition::new(5, 29)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(8, 29)),
        CharacterSequenceToken::build_token(String::from("object"), FilePosition::new(9, 29)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(15, 29)),
        CharacterSequenceToken::build_token(String::from("utils"), FilePosition::new(16, 29)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(21, 29)),
        CharacterSequenceToken::build_token(String::from("svaunit"), FilePosition::new(22, 29)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(29, 29)),
        CharacterSequenceToken::build_token(String::from("seq"), FilePosition::new(30, 29)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(33, 29)),
        KeywordToken::build_token(Keyword::Function, FilePosition::new(4, 36)),
        KeywordToken::build_token(Keyword::New, FilePosition::new(13, 36)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(16, 36)),
        KeywordToken::build_token(Keyword::String, FilePosition::new(17, 36)),
        CharacterSequenceToken::build_token(String::from("name"), FilePosition::new(24, 36)),
        OperatorToken::build_token(Operator::BinaryAssignment, FilePosition::new(29, 36)),
        StringLiteralToken::build_token(String::from("svaunit_seq"), FilePosition::new(31, 36)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(44, 36)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(45, 36)),
        KeywordToken::build_token(Keyword::Super, FilePosition::new(7, 37)),
        PunctuationToken::build_token(Punctuation::Period, FilePosition::new(12, 37)),
        KeywordToken::build_token(Keyword::New, FilePosition::new(13, 37)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(16, 37)),
        CharacterSequenceToken::build_token(String::from("name"), FilePosition::new(17, 37)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(21, 37)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(22, 37)),
        KeywordToken::build_token(Keyword::Endfunction, FilePosition::new(4, 40)),
        KeywordToken::build_token(Keyword::Virtual, FilePosition::new(4, 42)),
        KeywordToken::build_token(Keyword::Task, FilePosition::new(12, 42)),
        CharacterSequenceToken::build_token(String::from("pre"), FilePosition::new(17, 42)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(20, 42)),
        CharacterSequenceToken::build_token(String::from("body"), FilePosition::new(21, 42)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(25, 42)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(26, 42)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(27, 42)),
        KeywordToken::build_token(Keyword::Super, FilePosition::new(7, 43)),
        PunctuationToken::build_token(Punctuation::Period, FilePosition::new(12, 43)),
        CharacterSequenceToken::build_token(String::from("pre"), FilePosition::new(13, 43)),
        PunctuationToken::build_token(Punctuation::Underscore, FilePosition::new(16, 43)),
        CharacterSequenceToken::build_token(String::from("body"), FilePosition::new(17, 43)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(21, 43)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(22, 43)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(23, 43)),
        KeywordToken::build_token(Keyword::Endtask, FilePosition::new(4, 46)),
        KeywordToken::build_token(Keyword::Virtual, FilePosition::new(4, 48)),
        KeywordToken::build_token(Keyword::Task, FilePosition::new(12, 48)),
        CharacterSequenceToken::build_token(String::from("body"), FilePosition::new(17, 48)),
        PunctuationToken::build_token(Punctuation::LeftParentheses, FilePosition::new(21, 48)),
        PunctuationToken::build_token(Punctuation::RightParentheses, FilePosition::new(22, 48)),
        PunctuationToken::build_token(Punctuation::Semicolon, FilePosition::new(23, 48)),
        KeywordToken::build_token(Keyword::Endtask, FilePosition::new(4, 50)),
        KeywordToken::build_token(Keyword::Endclass, FilePosition::new(1, 51)),
        PunctuationToken::build_token(Punctuation::Backtick, FilePosition::new(1, 53)),
        CharacterSequenceToken::build_token(String::from("endif"), FilePosition::new(2, 53)),
        Token::EOF(FilePosition::new(1, 54)),
    ];

    let file_path = "./programs/svaunit_seq.sv";
    let mut lexer = Lexer::open(file_path);

    let tokens = lexer.lex();

    for (i, token) in tokens.iter().enumerate() {
        assert_eq!(token, &expected_tokens[i]);
    }
}
